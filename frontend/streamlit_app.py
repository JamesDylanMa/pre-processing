"""
Streamlit frontend application
"""
import streamlit as st
import os
import sys
from pathlib import Path
import time
from datetime import datetime
import json
import zipfile
from io import BytesIO

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

from backend.file_upload import FileUploadHandler
from backend.storage import StorageManager
from processing.parsers.pdf_parser import PDFParser
from processing.parsers.word_parser import WordParser
from processing.parsers.excel_parser import ExcelParser
from processing.parsers.ppt_parser import PPTParser
# Additional parsers will be imported conditionally
from processing.processors.document_ai import DocumentAIProcessor
from processing.processors.ensemble_processor import EnsembleProcessor
from processing.ollama_integration import OllamaProcessor
from processing.comparison import ResultComparator
from config import ALLOWED_EXTENSIONS, OUTPUT_FORMATS, OLLAMA_MODELS
from utils.file_utils import get_file_type

# Initialize comparator for scoring
comparator = ResultComparator()


# Page configuration
st.set_page_config(
    page_title="ë¬¸ì„œ ì „ì²˜ë¦¬ ì„œë¹„ìŠ¤",
    page_icon="ğŸ“„",
    layout="wide"
)

# Initialize session state
if 'file_metadata' not in st.session_state:
    st.session_state.file_metadata = None
if 'processing_results' not in st.session_state:
    st.session_state.processing_results = []
if 'session_id' not in st.session_state:
    st.session_state.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []  # ì—¬ëŸ¬ íŒŒì¼ ì²˜ë¦¬ ê¸°ë¡
if 'current_file_id' not in st.session_state:
    st.session_state.current_file_id = None


def process_single_file(uploaded_file, upload_handler, storage, file_session_id, 
                       use_ensemble, use_ollama, ollama_model, output_format):
    """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜"""
    # Save uploaded file
    metadata = upload_handler.save_uploaded_file(uploaded_file, file_session_id)
    
    # Process file
    results = []
    file_path = metadata["file_path"]
    file_type = metadata["file_type"]
    
    # Base processing with appropriate parser (pdfplumber)
    parsers = {
        'pdf': PDFParser(),
        'word': WordParser(),
        'excel': ExcelParser(),
        'powerpoint': PPTParser()
    }
    parser = parsers.get(file_type)
    if parser:
        base_result = parser.parse(file_path)
        base_result["processing_time"] = time.time()
        base_result["processor"] = "base_parser_pdfplumber"
        results.append(base_result)
    
    # Additional PDF parsers for comparison (PDF only)
    if file_type == 'pdf':
        # PyMuPDF parser (fast and accurate)
        try:
            from processing.parsers.pdf_pymupdf_parser import PyMuPDFParser
            pymupdf_parser = PyMuPDFParser()
            pymupdf_result = pymupdf_parser.parse(file_path)
            if "error" not in pymupdf_result:
                pymupdf_result["processing_time"] = time.time()
                pymupdf_result["processor"] = "pymupdf_parser"
                results.append(pymupdf_result)
        except ImportError:
            pass
        
        # PDFMiner parser (good for text extraction)
        try:
            from processing.parsers.pdf_pdfminer_parser import PDFMinerParser
            pdfminer_parser = PDFMinerParser()
            pdfminer_result = pdfminer_parser.parse(file_path)
            if "error" not in pdfminer_result:
                pdfminer_result["processing_time"] = time.time()
                pdfminer_result["processor"] = "pdfminer_parser"
                results.append(pdfminer_result)
        except (ImportError, Exception):
            pass
        
        # pypdf parser (modern PyPDF2 successor)
        try:
            from processing.parsers.pdf_pypdf_parser import PyPDFParser
            pypdf_parser = PyPDFParser()
            pypdf_result = pypdf_parser.parse(file_path)
            if "error" not in pypdf_result:
                pypdf_result["processing_time"] = time.time()
                pypdf_result["processor"] = "pypdf_parser"
                results.append(pypdf_result)
        except (ImportError, Exception):
            pass
    
    # AI processing
    ai_processor = DocumentAIProcessor()
    ai_result = ai_processor.process(file_path, file_type)
    ai_result["processing_time"] = time.time()
    results.append(ai_result)
    
    # Ensemble processing
    if use_ensemble:
        ensemble_processor = EnsembleProcessor()
        ensemble_result = ensemble_processor.process(file_path, file_type)
        ensemble_result["processing_time"] = time.time()
        results.append(ensemble_result)
    
    # Additional PDF parsers for table extraction (PDF only) - Optional
    if file_type == 'pdf':
        # Camelot parser (table extraction) - requires Java and OpenCV
        try:
            from processing.parsers.pdf_camelot_parser import CamelotParser
            camelot_parser = CamelotParser()
            camelot_result = camelot_parser.parse(file_path)
            if "error" not in camelot_result and camelot_result.get("tables"):
                camelot_result["processing_time"] = time.time()
                camelot_result["processor"] = "camelot_parser"
                results.append(camelot_result)
        except (ImportError, Exception) as e:
            pass
        
        # Tabula parser (table extraction) - requires Java
        try:
            from processing.parsers.pdf_tabula_parser import TabulaParser
            tabula_parser = TabulaParser()
            tabula_result = tabula_parser.parse(file_path)
            if "error" not in tabula_result and tabula_result.get("tables"):
                tabula_result["processing_time"] = time.time()
                tabula_result["processor"] = "tabula_parser"
                results.append(tabula_result)
        except (ImportError, Exception) as e:
            pass
        
        # EasyOCR parser (better OCR alternative, no external dependencies)
        try:
            from processing.parsers.pdf_easyocr_parser import EasyOCRParser
            easyocr_parser = EasyOCRParser()
            if easyocr_parser.reader is not None:  # Only use if reader initialized successfully
                easyocr_result = easyocr_parser.parse(file_path)
                if "error" not in easyocr_result and (easyocr_result.get("text") or easyocr_result.get("pages")):
                easyocr_result["processing_time"] = time.time()
                easyocr_result["processor"] = "easyocr_parser"
                results.append(easyocr_result)
        except (ImportError, Exception) as e:
            pass
        
        # OCR parser (for scanned PDFs) - requires Tesseract (fallback)
        try:
            from processing.parsers.pdf_ocr_parser import OCRParser
            ocr_parser = OCRParser()
            ocr_result = ocr_parser.parse(file_path)
            if "error" not in ocr_result:
                ocr_result["processing_time"] = time.time()
                ocr_result["processor"] = "ocr_parser"
                results.append(ocr_result)
        except (ImportError, Exception) as e:
            pass
        
        # Unstructured parser (advanced document structure extraction)
        try:
            from processing.parsers.pdf_unstructured_parser import UnstructuredParser
            unstructured_parser = UnstructuredParser()
            unstructured_result = unstructured_parser.parse(file_path)
            if "error" not in unstructured_result:
                unstructured_result["processing_time"] = time.time()
                unstructured_result["processor"] = "unstructured_parser"
                results.append(unstructured_result)
        except (ImportError, Exception) as e:
            pass
        
        # PDFQuery parser (CSS-like selectors for structured PDFs)
        try:
            from processing.parsers.pdf_pdfquery_parser import PDFQueryParser
            pdfquery_parser = PDFQueryParser()
            pdfquery_result = pdfquery_parser.parse(file_path)
            if "error" not in pdfquery_result:
                pdfquery_result["processing_time"] = time.time()
                pdfquery_result["processor"] = "pdfquery_parser"
                results.append(pdfquery_result)
        except (ImportError, Exception) as e:
            pass
    
    # Ollama processing
    if use_ollama and ollama_model:
        ollama_processor = OllamaProcessor(ollama_model)
        if ollama_processor.is_available():
            ollama_result = ollama_processor.process_document(file_path, file_type)
            if ollama_result and "error" not in ollama_result:
                ollama_result["processing_time"] = time.time()
                ollama_result["processor"] = f"ollama_{ollama_model}"
                results.append(ollama_result)
    
    # Filter out results with errors or empty results
    valid_results = [r for r in results if "error" not in r and (r.get("text") or r.get("tables") or r.get("pages") or r.get("metadata"))]
    
    # Score and sort results by quality
    sorted_results = comparator.score_and_sort_results(valid_results)
    
    # Save results
    saved_files = []
    original_filename = metadata.get("original_name", "")
    for result in sorted_results:
        processor_name = result.get("processor") or result.get("parser")
        if not processor_name:
            continue  # Skip results without processor name
        saved_path = storage.save_result(
            result,
            metadata["file_id"],
            processor_name,
            output_format,
            original_filename=original_filename
        )
        saved_files.append(saved_path)
    
    # íŒŒì¼ ê²°ê³¼ ë°˜í™˜ (ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼)
    file_result = {
        "file_id": metadata["file_id"],
        "file_name": metadata["original_name"],
        "file_type": metadata["file_type"],
        "results": sorted_results,  # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼
        "metadata": metadata
    }
    
    return file_result


def main():
    st.title("ğŸ“„ ë¬¸ì„œ ì „ì²˜ë¦¬ ì„œë¹„ìŠ¤")
    st.markdown("---")
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # Processing options
        st.subheader("ì²˜ë¦¬ ì˜µì…˜")
        use_ensemble = st.checkbox("ì•™ìƒë¸” ì²˜ë¦¬ ì‚¬ìš©", value=True)
        use_comparison = st.checkbox("ê²°ê³¼ ë¹„êµ í™œì„±í™”", value=True)
        use_ollama = st.checkbox("Ollama AI ì²˜ë¦¬ ì‚¬ìš©", value=False)
        
        # Ollama settings
        if use_ollama:
            st.subheader("Ollama ì„¤ì •")
            ollama_model = st.selectbox(
                "ëª¨ë¸ ì„ íƒ",
                options=OLLAMA_MODELS["multimodal"] + OLLAMA_MODELS["text"],
                index=0
            )
        else:
            ollama_model = None
        
        # Output format
        st.subheader("ì¶œë ¥ í˜•ì‹")
        output_format = st.selectbox("ì €ì¥ í˜•ì‹", OUTPUT_FORMATS, index=0)
        
        st.markdown("---")
        st.info(f"ê¶Œì¥ ëª¨ë¸: {OLLAMA_MODELS['recommended']}")
    
    # Main content area
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ”„ ì²˜ë¦¬ ê²°ê³¼", "ğŸ“Š ë¹„êµ ë¶„ì„", "ğŸ“¥ ë‹¤ìš´ë¡œë“œ"])
    
    with tab1:
        st.header("íŒŒì¼ ì—…ë¡œë“œ")
        
        # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
        if 'last_success_message' in st.session_state and st.session_state.last_success_message:
            st.success(st.session_state.last_success_message)
            del st.session_state.last_success_message
        
        # ì‚­ì œ ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
        if 'delete_success_message' in st.session_state and st.session_state.delete_success_message:
            st.success(st.session_state.delete_success_message)
            del st.session_state.delete_success_message
        
        # ì²˜ë¦¬ëœ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        if st.session_state.processed_files:
            st.subheader("ğŸ“‹ ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡")
            for idx, file_info in enumerate(st.session_state.processed_files):
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                with col1:
                    file_icon = "ğŸ“„" if file_info["file_type"] == "pdf" else "ğŸ“" if file_info["file_type"] == "word" else "ğŸ“Š" if file_info["file_type"] == "excel" else "ğŸ“‘" if file_info["file_type"] == "powerpoint" else "ğŸ“"
                    st.write(f"{file_icon} **{file_info['file_name']}** ({file_info['file_type']})")
                with col2:
                    st.write(f"`{len(file_info['results'])}ê°œ ê²°ê³¼`")
                with col3:
                    if st.button("ë³´ê¸°", key=f"view_{file_info['file_id']}"):
                        st.session_state.processing_results = file_info["results"]
                        st.session_state.file_metadata = file_info["metadata"]
                        st.session_state.current_file_id = file_info["file_id"]
                        st.rerun()
                with col4:
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{file_info['file_id']}"):
                        try:
                            upload_handler = FileUploadHandler()
                            session_id = file_info["metadata"].get("session_id")
                            if not session_id:
                                file_path = Path(file_info["metadata"]["file_path"])
                                if file_path.parent.name != "uploads":
                                    session_id = file_path.parent.name
                            
                            upload_handler.delete_file(file_info["file_id"], session_id)
                            
                            storage = StorageManager()
                            result_files = storage.get_results_for_file(file_info["file_id"])
                            for result_file in result_files:
                                try:
                                    result_file.unlink()
                                except:
                                    pass
                            
                            st.session_state.processed_files.pop(idx)
                            
                            if st.session_state.current_file_id == file_info["file_id"]:
                                if st.session_state.processed_files:
                                    first_file = st.session_state.processed_files[0]
                                    st.session_state.processing_results = first_file["results"]
                                    st.session_state.file_metadata = first_file["metadata"]
                                    st.session_state.current_file_id = first_file["file_id"]
                                else:
                                    st.session_state.processing_results = []
                                    st.session_state.file_metadata = None
                                    st.session_state.current_file_id = None
                            
                            st.session_state.delete_success_message = f"íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤: {file_info['file_name']}"
                            st.rerun()
                        except Exception as e:
                            st.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.divider()
        
        # ì—¬ëŸ¬ íŒŒì¼ ì—…ë¡œë“œ ì§€ì›
        uploaded_files = st.file_uploader(
            "ë¬¸ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì—¬ëŸ¬ íŒŒì¼ ì„ íƒ ê°€ëŠ¥)",
            type=['pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx', 'txt', 'md', 'png', 'jpg', 'jpeg'],
            help="ì§€ì› í˜•ì‹: PDF, Word, Excel, PowerPoint, í…ìŠ¤íŠ¸, ì´ë¯¸ì§€. ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            key="file_uploader",
            accept_multiple_files=True
        )
        
        # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
        if uploaded_files and len(uploaded_files) > 0:
            st.subheader(f"ğŸ“ ì„ íƒëœ íŒŒì¼ ({len(uploaded_files)}ê°œ)")
            for idx, file in enumerate(uploaded_files):
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    file_icon = "ğŸ“„" if file.name.lower().endswith('.pdf') else "ğŸ“" if file.name.lower().endswith(('.doc', '.docx')) else "ğŸ“Š" if file.name.lower().endswith(('.xls', '.xlsx')) else "ğŸ“‘" if file.name.lower().endswith(('.ppt', '.pptx')) else "ğŸ“"
                    st.write(f"{file_icon} **{file.name}** ({file.size / 1024:.2f} KB)")
                with col2:
                    file_type = get_file_type(file.name)
                    st.write(f"`{file_type or 'ì•Œ ìˆ˜ ì—†ìŒ'}`")
                with col3:
                    st.write("âœ… ì¤€ë¹„ë¨")
        
        if uploaded_files and len(uploaded_files) > 0:
            # Upload button
            if st.button(f"ğŸ“¤ {len(uploaded_files)}ê°œ íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì‹œì‘", type="primary", key="upload_button"):
                try:
                    upload_handler = FileUploadHandler()
                    storage = StorageManager()
                    
                    processed_count = 0
                    failed_files = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for file_idx, uploaded_file in enumerate(uploaded_files):
                        try:
                            status_text.text(f"ì²˜ë¦¬ ì¤‘: {uploaded_file.name} ({file_idx + 1}/{len(uploaded_files)})")
                            progress_bar.progress((file_idx) / len(uploaded_files))
                            
                            file_session_id = f"{st.session_state.session_id}_{datetime.now().strftime('%H%M%S%f')}"
                            
                            # íŒŒì¼ ì²˜ë¦¬
                            file_result = process_single_file(
                                uploaded_file, upload_handler, storage, file_session_id,
                                use_ensemble, use_ollama, ollama_model, output_format
                            )
                            
                            # ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
                            existing_index = next(
                                (i for i, f in enumerate(st.session_state.processed_files) 
                                 if f["file_id"] == file_result["file_id"]), 
                                None
                            )
                            
                            if existing_index is not None:
                                st.session_state.processed_files[existing_index] = file_result
                            else:
                                st.session_state.processed_files.append(file_result)
                            
                            processed_count += 1
                            
                        except Exception as e:
                            failed_files.append((uploaded_file.name, str(e)))
                    
                    progress_bar.progress(1.0)
                    status_text.empty()
                    
                    # ì„±ê³µ ë©”ì‹œì§€
                    if processed_count > 0:
                        st.session_state.last_success_message = f"âœ… {processed_count}ê°œ íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
                        if failed_files:
                            st.session_state.last_success_message += f" ({len(failed_files)}ê°œ ì‹¤íŒ¨)"
                    
                    # ì‹¤íŒ¨í•œ íŒŒì¼ í‘œì‹œ
                    if failed_files:
                        for file_name, error in failed_files:
                            st.error(f"âŒ {file_name}: {error}")
                    
                    # ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ íŒŒì¼ì„ í˜„ì¬ íŒŒì¼ë¡œ ì„¤ì •
                    if st.session_state.processed_files:
                        last_file = st.session_state.processed_files[-1]
                        st.session_state.processing_results = last_file["results"]
                        st.session_state.file_metadata = last_file["metadata"]
                        st.session_state.current_file_id = last_file["file_id"]
                    
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
    
    with tab2:
        st.header("ì²˜ë¦¬ ê²°ê³¼")
        
        # ì—¬ëŸ¬ íŒŒì¼ì´ ì²˜ë¦¬ëœ ê²½ìš° ì„ íƒí•  ìˆ˜ ìˆë„ë¡
        if st.session_state.processed_files:
            if len(st.session_state.processed_files) > 1:
                file_options = [f"{f['file_name']} ({f['file_type']})" for f in st.session_state.processed_files]
                selected_file_index = st.selectbox(
                    "ì²˜ë¦¬ëœ íŒŒì¼ ì„ íƒ",
                    options=range(len(st.session_state.processed_files)),
                    format_func=lambda x: file_options[x],
                    key="file_selector"
                )
                selected_file = st.session_state.processed_files[selected_file_index]
                st.session_state.processing_results = selected_file["results"]
                st.session_state.file_metadata = selected_file["metadata"]
                st.session_state.current_file_id = selected_file["file_id"]
            else:
                selected_file = st.session_state.processed_files[0]
                st.session_state.processing_results = selected_file["results"]
                st.session_state.file_metadata = selected_file["metadata"]
                st.session_state.current_file_id = selected_file["file_id"]
        
        if st.session_state.processing_results:
            # ì—ëŸ¬ê°€ ìˆëŠ” ê²°ê³¼ í•„í„°ë§
            valid_results = [r for r in st.session_state.processing_results 
                           if "error" not in r and (r.get("text") or r.get("tables") or r.get("pages") or r.get("metadata"))]
            
            if not valid_results:
                st.warning("ìœ íš¨í•œ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                return
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼ í‘œì‹œ
            sorted_display_results = comparator.score_and_sort_results(valid_results)
            
            for i, result in enumerate(sorted_display_results):
                processor_name = result.get("processor") or result.get("parser")
                if not processor_name:
                    continue  # í”„ë¡œì„¸ì„œ ì´ë¦„ì´ ì—†ëŠ” ê²°ê³¼ëŠ” ê±´ë„ˆë›°ê¸°
                
                name_mapping = {
                    "pdf_parser": "PDF Parser (pdfplumber)",
                    "pymupdf_parser": "PDF Parser (PyMuPDF)",
                    "pdfminer_parser": "PDF Parser (pdfminer)",
                    "pypdf_parser": "PDF Parser (pypdf)",
                    "easyocr_parser": "PDF Parser (EasyOCR - Better OCR)",
                    "ocr_parser": "PDF Parser (OCR - Tesseract)",
                    "unstructured_parser": "PDF Parser (Unstructured - Advanced)",
                    "pdfquery_parser": "PDF Parser (PDFQuery - CSS Selectors)",
                    "camelot_parser": "PDF Parser (Camelot - Tables)",
                    "tabula_parser": "PDF Parser (Tabula - Tables)",
                    "document_ai": "Document AI Processor",
                    "ensemble_processor": "Ensemble Processor",
                    "base_parser_pdfplumber": "Base Parser (pdfplumber)",
                    "word_parser": "Word Parser",
                    "excel_parser": "Excel Parser",
                    "ppt_parser": "PowerPoint Parser"
                }
                if processor_name.startswith("ollama_"):
                    model_name = processor_name.replace("ollama_", "")
                    processor_name = f"Ollama AI ({model_name})"
                else:
                    processor_name = name_mapping.get(processor_name, processor_name)
                
                with st.expander(f"ğŸ“‹ {processor_name} ê²°ê³¼", expanded=(i == 0)):
                    if result.get("text"):
                        st.subheader("ì¶”ì¶œëœ í…ìŠ¤íŠ¸")
                        st.text_area(
                            "í…ìŠ¤íŠ¸ ë‚´ìš©",
                            value=result["text"][:5000] + ("..." if len(result["text"]) > 5000 else ""),
                            height=200,
                            disabled=True,
                            key=f"text_area_{i}_{processor_name}"
                        )
                    
                    if result.get("metadata"):
                        st.subheader("ë©”íƒ€ë°ì´í„°")
                        st.json(result["metadata"])
                    
                    if result.get("tables"):
                        st.subheader("ì¶”ì¶œëœ í…Œì´ë¸”")
                        for j, table in enumerate(result["tables"][:3]):
                            st.dataframe(table.get("rows", []), key=f"table_{i}_{j}")
                    
                    if result.get("sheets"):
                        st.subheader("ì‹œíŠ¸ ì •ë³´")
                        for k, sheet in enumerate(result["sheets"][:3]):
                            st.write(f"**ì‹œíŠ¸ëª…**: {sheet['sheet_name']}")
                            if sheet.get("data"):
                                st.dataframe(sheet["data"][:100], key=f"sheet_{i}_{k}")
        else:
            st.info("ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.header("ë¹„êµ ë¶„ì„")
        
        if st.session_state.processed_files:
            if len(st.session_state.processed_files) > 1:
                file_options = [f"{f['file_name']} ({f['file_type']})" for f in st.session_state.processed_files]
                selected_file_index = st.selectbox(
                    "ë¹„êµí•  íŒŒì¼ ì„ íƒ",
                    options=range(len(st.session_state.processed_files)),
                    format_func=lambda x: file_options[x],
                    key="comparison_file_selector"
                )
                selected_file = st.session_state.processed_files[selected_file_index]
                comparison_results = selected_file["results"]
            else:
                comparison_results = st.session_state.processed_files[0]["results"]
        else:
            comparison_results = st.session_state.processing_results
        
        if len(comparison_results) > 1 and use_comparison:
            comparison = comparator.compare_results(comparison_results)
            
            if comparison.get("comparison_metrics"):
                import pandas as pd
                df = pd.DataFrame(comparison["comparison_metrics"])
                st.dataframe(df, key="comparison_metrics_df")
            
            if comparison.get("recommendations"):
                st.subheader("ì¶”ì²œ ì‚¬í•­")
                for rec in comparison["recommendations"]:
                    st.info(rec)
            
            if comparison.get("best_processor"):
                st.subheader("ìµœì  ì²˜ë¦¬ê¸°")
                best = comparison["best_processor"]
                st.success(f"**{best['processor']}** (ì ìˆ˜: {best['score']:.2f})")
                st.json(best["metrics"])
            
            if st.button("ë¹„êµ ê²°ê³¼ ì €ì¥", key="save_comparison_button"):
                storage = StorageManager()
                if st.session_state.processed_files:
                    if len(st.session_state.processed_files) > 1:
                        selected_file_index = st.session_state.get("comparison_file_selector", 0)
                        file_id = st.session_state.processed_files[selected_file_index]["file_id"]
                    else:
                        file_id = st.session_state.processed_files[0]["file_id"]
                elif st.session_state.file_metadata:
                    file_id = st.session_state.file_metadata["file_id"]
                else:
                    st.error("íŒŒì¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    file_id = None
                
                if file_id:
                    saved_path = storage.save_comparison_result(comparison, file_id)
                    st.success(f"ë¹„êµ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {saved_path.name}")
        else:
            st.info("ë¹„êµë¥¼ ìœ„í•´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì²˜ë¦¬ ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    with tab4:
        st.header("ë‹¤ìš´ë¡œë“œ")
        
        storage = StorageManager()
        
        if st.session_state.processed_files:
            if len(st.session_state.processed_files) > 1:
                file_options = [f"{f['file_name']} ({f['file_type']})" for f in st.session_state.processed_files]
                selected_file_index = st.selectbox(
                    "ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ ì„ íƒ",
                    options=range(len(st.session_state.processed_files)),
                    format_func=lambda x: file_options[x],
                    key="download_file_selector"
                )
                selected_file = st.session_state.processed_files[selected_file_index]
                file_id = selected_file["file_id"]
                file_name = selected_file["file_name"]
                processing_results = selected_file["results"]
            else:
                file_id = st.session_state.processed_files[0]["file_id"]
                file_name = st.session_state.processed_files[0]["file_name"]
                processing_results = st.session_state.processed_files[0]["results"]
            
            result_files = storage.get_results_for_file(file_id)
            
            if processing_results:
                st.subheader(f"ğŸ“¦ {file_name} - ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                
                # íŒŒì¼ë³„ë¡œ ì •ë¦¬ëœ ë‹¤ìš´ë¡œë“œ
                base_filename = Path(file_name).stem
                safe_base_name = "".join(c for c in base_filename if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
                
                # í”„ë¡œì„¸ì„œ ì´ë¦„ ë§¤í•‘
                name_mapping = {
                    "pdf_parser": "pdfplumber",
                    "pymupdf_parser": "pymupdf",
                    "pdfminer_parser": "pdfminer",
                    "pypdf_parser": "pypdf",
                    "easyocr_parser": "easyocr",
                    "ocr_parser": "ocr_tesseract",
                    "unstructured_parser": "unstructured",
                    "pdfquery_parser": "pdfquery",
                    "camelot_parser": "camelot",
                    "tabula_parser": "tabula",
                    "document_ai": "document_ai",
                    "ensemble_processor": "ensemble",
                    "base_parser_pdfplumber": "base_pdfplumber",
                    "word_parser": "word",
                    "excel_parser": "excel",
                    "ppt_parser": "powerpoint"
                }
                
                # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ê²°ê³¼ ì‚¬ìš©
                sorted_results = comparator.score_and_sort_results(processing_results)
                
                # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì ìˆ˜ ë†’ì€ ìˆœì„œëŒ€ë¡œ)
                st.write("**ê°œë³„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (ì ìˆ˜ ìˆœ):**")
                for i, result in enumerate(sorted_results):
                    processor_name = result.get("processor") or result.get("parser") or f"processor_{i+1}"
                    
                    if processor_name.startswith("ollama_"):
                        safe_name = processor_name.replace("ollama_", "ollama_")
                    else:
                        safe_name = name_mapping.get(processor_name, processor_name.replace(" ", "_").lower())
                    
                    display_name = name_mapping.get(processor_name, processor_name)
                    if processor_name.startswith("ollama_"):
                        display_name = f"Ollama ({processor_name.replace('ollama_', '')})"
                    
                    col1, col2, col3 = st.columns([3, 1, 1])
                    with col1:
                        st.write(f"â€¢ {display_name}")
                    with col2:
                        json_data = json.dumps(result, ensure_ascii=False, indent=2)
                        json_bytes = json_data.encode('utf-8')
                        st.download_button(
                            "ğŸ“¥ JSON",
                            json_bytes,
                            file_name=f"{safe_base_name}_{safe_name}.json",
                            key=f"json_download_{file_id}_{i}",
                            mime="application/json"
                        )
                    with col3:
                        md_content = storage._dict_to_markdown(result)
                        md_bytes = md_content.encode('utf-8')
                        st.download_button(
                            "ğŸ“¥ MD",
                            md_bytes,
                            file_name=f"{safe_base_name}_{safe_name}.md",
                            key=f"md_download_{file_id}_{i}",
                            mime="text/markdown"
                        )
                
                st.divider()
                
                # íŒŒì¼ë³„ ZIP ë‹¤ìš´ë¡œë“œ (ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ZIPìœ¼ë¡œ, ì ìˆ˜ ìˆœ)
                st.write("**ì „ì²´ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ (ì ìˆ˜ ìˆœ):**")
                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    # JSON íŒŒì¼ë“¤ ì¶”ê°€ (ì ìˆ˜ ë†’ì€ ìˆœì„œëŒ€ë¡œ)
                    for i, result in enumerate(sorted_results):
                        processor_name = result.get("processor") or result.get("parser") or f"processor_{i+1}"
                        if processor_name.startswith("ollama_"):
                            safe_name = processor_name.replace("ollama_", "ollama_")
                        else:
                            safe_name = name_mapping.get(processor_name, processor_name.replace(" ", "_").lower())
                        
                        json_data = json.dumps(result, ensure_ascii=False, indent=2)
                        zip_file.writestr(f"{safe_base_name}_{safe_name}.json", json_data.encode('utf-8'))
                        
                        md_content = storage._dict_to_markdown(result)
                        zip_file.writestr(f"{safe_base_name}_{safe_name}.md", md_content.encode('utf-8'))
                
                zip_buffer.seek(0)
                st.download_button(
                    "ğŸ“¦ ì „ì²´ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ (JSON + MD)",
                    zip_buffer.getvalue(),
                    file_name=f"{safe_base_name}_all_results.zip",
                    key=f"zip_download_{file_id}",
                    mime="application/zip"
                )
                
                # ì €ì¥ëœ íŒŒì¼ë„ í‘œì‹œ
                if result_files:
                    st.divider()
                    st.subheader(f"ì €ì¥ëœ íŒŒì¼: {file_name}")
                    for result_file in result_files:
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.write(f"ğŸ“„ {result_file.name}")
                        with col2:
                            with open(result_file, "rb") as f:
                                st.download_button(
                                    "ë‹¤ìš´ë¡œë“œ",
                                    f.read(),
                                    file_name=result_file.name,
                                    key=f"download_saved_{file_id}_{result_file.name}",
                                    mime="application/json" if result_file.suffix == ".json" else "text/markdown"
                                )
            elif result_files:
                st.subheader(f"ì €ì¥ëœ ê²°ê³¼ íŒŒì¼: {file_name}")
                for result_file in result_files:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"ğŸ“„ {result_file.name}")
                    with col2:
                        with open(result_file, "rb") as f:
                            st.download_button(
                                "ë‹¤ìš´ë¡œë“œ",
                                f.read(),
                                file_name=result_file.name,
                                key=f"download_{file_id}_{result_file.name}",
                                mime="application/json" if result_file.suffix == ".json" else "text/markdown"
                            )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        
        elif st.session_state.processing_results:
            file_name = st.session_state.file_metadata.get("original_name", "unknown") if st.session_state.file_metadata else "unknown"
            st.subheader("ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            base_filename = Path(file_name).stem
            safe_base_name = "".join(c for c in base_filename if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
            
            name_mapping = {
                "pdf_parser": "pdfplumber",
                "pymupdf_parser": "pymupdf",
                "pdfminer_parser": "pdfminer",
                "pypdf_parser": "pypdf",
                "easyocr_parser": "easyocr",
                "ocr_parser": "ocr_tesseract",
                "unstructured_parser": "unstructured",
                "pdfquery_parser": "pdfquery",
                "camelot_parser": "camelot",
                "tabula_parser": "tabula",
                "document_ai": "document_ai",
                "ensemble_processor": "ensemble",
                "base_parser_pdfplumber": "base_pdfplumber"
            }
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_results = comparator.score_and_sort_results(st.session_state.processing_results)
            
            for i, result in enumerate(sorted_results):
                processor_name = result.get("processor") or result.get("parser") or f"Processor_{i+1}"
                safe_name = name_mapping.get(processor_name, processor_name.replace(" ", "_").lower())
                
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"**{processor_name}**")
                with col2:
                    json_data = json.dumps(result, ensure_ascii=False, indent=2)
                    json_bytes = json_data.encode('utf-8')
                    st.download_button(
                        "ğŸ“¥ JSON",
                        json_bytes,
                        file_name=f"{safe_base_name}_{safe_name}.json",
                        key=f"json_download_direct_{i}",
                        mime="application/json"
                    )
                with col3:
                    md_content = storage._dict_to_markdown(result)
                    md_bytes = md_content.encode('utf-8')
                    st.download_button(
                        "ğŸ“¥ MD",
                        md_bytes,
                        file_name=f"{safe_base_name}_{safe_name}.md",
                        key=f"md_download_direct_{i}",
                        mime="text/markdown"
                    )
                st.divider()
        
        elif st.session_state.file_metadata:
            file_id = st.session_state.file_metadata["file_id"]
            result_files = storage.get_results_for_file(file_id)
            
            if result_files:
                st.subheader("ì €ì¥ëœ ê²°ê³¼ íŒŒì¼")
                for result_file in result_files:
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.write(f"ğŸ“„ {result_file.name}")
                    with col2:
                        with open(result_file, "rb") as f:
                            st.download_button(
                                "ë‹¤ìš´ë¡œë“œ",
                                f.read(),
                                file_name=result_file.name,
                                key=f"download_{result_file.name}",
                                mime="application/json" if result_file.suffix == ".json" else "text/markdown"
                            )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        else:
            st.info("ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì—…ë¡œë“œ íƒ­ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
